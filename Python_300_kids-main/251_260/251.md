## 251 - Viết chương trình để tải xuống trang web

### Giải thích đề bài

Đề bài yêu cầu viết một chương trình Python để thực hiện **web scraping** cơ bản: tải xuống nội dung của một trang web và phân tích dữ liệu từ đó.

Web scraping là kỹ thuật tự động thu thập thông tin từ các trang web. Trong trường hợp này, chương trình sẽ gửi yêu cầu tới một URL, nhận về nội dung HTML và có thể trích xuất một số thông tin cụ thể từ đó.

### Thuật toán:

#### Đầu vào:
- URL của trang web cần tải xuống.
- (Tuỳ chọn) Các thông tin cụ thể cần trích xuất từ trang web, ví dụ như tiêu đề (title), tất cả các liên kết (links), hoặc các đoạn văn bản (paragraphs).

#### Đầu ra:
- Nội dung HTML của trang web, có thể được lưu vào một tệp hoặc in ra màn hình.
- (Tuỳ chọn) Các thông tin cụ thể được trích xuất từ trang web.

#### Các bước thực hiện:
1. **Nhập liệu**: Người dùng nhập URL của trang web cần tải xuống.
2. **Gửi yêu cầu HTTP**: Sử dụng thư viện `requests` để gửi yêu cầu GET tới URL đó.
3. **Xử lý phản hồi**: Kiểm tra nếu yêu cầu thành công (mã trạng thái HTTP 200).
4. **Lưu nội dung HTML**: Lưu nội dung HTML của trang web vào một tệp hoặc in ra màn hình.
5. **Phân tích và trích xuất dữ liệu**: Sử dụng `BeautifulSoup` để phân tích cú pháp HTML và trích xuất thông tin cụ thể nếu cần.

### Cài đặt thư viện

Chúng ta cần cài đặt các thư viện `requests` để gửi yêu cầu HTTP và `beautifulsoup4` để phân tích cú pháp HTML.

```bash
pip install requests beautifulsoup4
```

### Code Python

```python
import requests
from bs4 import BeautifulSoup

# Nhập URL của trang web cần tải xuống
url = input("Nhập URL của trang web cần tải xuống: ")

# Tên tệp để lưu nội dung HTML
output_file = "downloaded_page.html"

try:
    # Gửi yêu cầu HTTP GET đến URL
    response = requests.get(url)

    # Kiểm tra nếu yêu cầu thành công (mã trạng thái 200)
    if response.status_code == 200:
        # Lưu nội dung HTML vào tệp
        with open(output_file, "w", encoding='utf-8') as file:
            file.write(response.text)
        print(f"Nội dung HTML của trang web đã được lưu vào tệp '{output_file}'.")

        # Phân tích cú pháp HTML bằng BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Trích xuất và in tiêu đề trang
        page_title = soup.title.string
        print(f"Tiêu đề trang web: {page_title}")

        # Trích xuất tất cả các liên kết (links) từ trang
        links = soup.find_all('a')
        print("\nCác liên kết (links) trên trang web:")
        for link in links:
            href = link.get('href')
            text = link.get_text(strip=True)
            print(f"Text: {text}, URL: {href}")

        # Trích xuất các đoạn văn bản (paragraphs)
        paragraphs = soup.find_all('p')
        print("\nCác đoạn văn bản (paragraphs) trên trang web:")
        for p in paragraphs:
            print(p.get_text(strip=True))

    else:
        print(f"Không thể tải xuống trang web. Mã trạng thái HTTP: {response.status_code}")

except Exception as e:
    print(f"Đã xảy ra lỗi: {e}")
```

### Giải thích code

1. **Nhập URL của trang web**:
   - Sử dụng `input()` để người dùng nhập URL của trang web mà họ muốn tải xuống.

2. **Định nghĩa tên tệp đầu ra**:
   - `output_file` là tên tệp mà nội dung HTML của trang web sẽ được lưu vào.

3. **Gửi yêu cầu HTTP GET**:
   - Sử dụng `requests.get(url)` để gửi yêu cầu GET tới URL nhập vào.

4. **Kiểm tra trạng thái phản hồi**:
   - Kiểm tra mã trạng thái của phản hồi bằng `response.status_code`.
   - Nếu mã trạng thái là 200, nghĩa là yêu cầu thành công.

5. **Lưu nội dung HTML vào tệp**:
   - Sử dụng `open(output_file, "w", encoding='utf-8')` để mở hoặc tạo tệp `output_file` trong chế độ ghi.
   - Sử dụng `file.write(response.text)` để ghi nội dung HTML nhận được từ phản hồi vào tệp.

6. **Phân tích cú pháp HTML**:
   - Sử dụng `BeautifulSoup` để phân tích cú pháp của nội dung HTML đã tải xuống (`response.text`).

7. **Trích xuất tiêu đề trang**:
   - Truy cập vào thẻ `<title>` của trang và lấy nội dung của nó.

8. **Trích xuất tất cả các liên kết**:
   - Sử dụng `soup.find_all('a')` để tìm tất cả các thẻ `<a>` trên trang web và trích xuất thuộc tính `href` và văn bản liên kết.

9. **Trích xuất các đoạn văn bản**:
   - Sử dụng `soup.find_all('p')` để tìm tất cả các thẻ `<p>` (đoạn văn) trên trang và lấy nội dung văn bản của chúng.

10. **Xử lý lỗi**:
    - Sử dụng khối `try-except` để bắt và xử lý các lỗi phát sinh trong quá trình gửi yêu cầu hoặc xử lý dữ liệu.

### Bổ sung
- Nếu cần tải xuống và phân tích nhiều trang, có thể mở rộng chương trình để lặp qua một danh sách các URL.
- Có thể bổ sung thêm tính năng lưu trữ các liên kết hoặc đoạn văn bản vào các tệp riêng biệt.

### Tóm tắt:
- Sử dụng thư viện `requests` để gửi yêu cầu HTTP GET.
- Sử dụng thư viện `BeautifulSoup` để phân tích cú pháp HTML.
- Sử dụng phương thức `open()` và `write()` để lưu nội dung HTML vào tệp.
- Sử dụng các phương thức của `BeautifulSoup` để trích xuất thông tin cụ thể từ HTML.
- Sử dụng cấu trúc `try-except` để xử lý lỗi.

Chương trình này tải xuống nội dung HTML của một trang web từ URL được cung cấp bởi người dùng, phân tích cú pháp HTML để trích xuất tiêu đề trang, các liên kết, và các đoạn văn bản, sau đó hiển thị hoặc lưu các thông tin này.