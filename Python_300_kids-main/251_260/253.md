## 253 - Viết chương trình để trích xuất tất cả các liên kết từ trang web

### Giải thích đề bài

Đề bài yêu cầu viết một chương trình Python để trích xuất tất cả các liên kết (URLs) từ một trang web cụ thể mà người dùng nhập vào.

### Thuật toán:

- **Đầu vào:**

  - URL của trang web cần trích xuất các liên kết (nhập từ người dùng).

- **Đầu ra:**

  - Danh sách các liên kết từ trang web.

- **Các bước thực hiện:**
  1. Cài đặt các thư viện cần thiết.
  2. Tạo một hàm để trích xuất tất cả các liên kết từ URL cung cấp.
  3. Gửi yêu cầu HTTP đến URL và nhận phản hồi.
  4. Phân tích phản hồi để trích xuất tất cả các liên kết.
  5. In ra danh sách các liên kết.

### Cài đặt thư viện

```
pip install requests beautifulsoup4
```

### Code Python

```python
import requests
from bs4 import BeautifulSoup

def extract_links(url):
    # Gửi yêu cầu HTTP tới URL
    response = requests.get(url)

    # Kiểm tra mã trạng thái HTTP
    if response.status_code == 200:
        # Phân tích nội dung HTML
        soup = BeautifulSoup(response.content, 'html.parser')

        # Trích xuất tất cả các liên kết
        links = []
        for link in soup.find_all('a', href=True):
            links.append(link['href'])

        # Trả về danh sách các liên kết
        return links
    else:
        return None

# Nhập URL của trang web từ người dùng
url = input("Nhập URL của trang web: ")
links = extract_links(url)
if links:
    print("Các liên kết trên trang web:")
    for link in links:
        print(link)
else:
    print("Không thể truy cập trang web hoặc trang web không có liên kết.")
```

### Giải thích code

1. **Cài đặt thư viện:**

   - `requests`: Thư viện này dùng để gửi các yêu cầu HTTP.
   - `beautifulsoup4`: Thư viện này dùng để phân tích cú pháp HTML và trích xuất dữ liệu từ đó.

2. **Hàm `extract_links(url)`:**

   - **Gửi yêu cầu HTTP tới URL**:
     - `requests.get(url)`: Gửi một yêu cầu GET tới URL và lưu trữ phản hồi.
   - **Kiểm tra mã trạng thái HTTP**:
     - `response.status_code == 200`: Kiểm tra xem phản hồi có thành công hay không (mã trạng thái 200).
   - **Phân tích nội dung HTML**:
     - `BeautifulSoup(response.content, 'html.parser')`: Phân tích nội dung HTML của trang web.
   - **Trích xuất tất cả các liên kết**:
     - `soup.find_all('a', href=True)`: Tìm tất cả các thẻ `<a>` có thuộc tính `href`.
     - Lặp qua các thẻ `<a>` và thêm giá trị của thuộc tính `href` vào danh sách `links`.
   - **Trả về danh sách các liên kết**: Trả về danh sách các liên kết nếu có, ngược lại trả về `None`.

3. **Sử dụng hàm `extract_links`**:
   - **Nhập URL của trang web từ người dùng**: Sử dụng hàm `input` để người dùng nhập URL.
   - **Gọi hàm `extract_links` và in danh sách các liên kết**:
     - Gọi hàm `extract_links` với URL đã nhập.
     - Kiểm tra và in danh sách các liên kết nếu có, ngược lại in thông báo lỗi.

### Bổ sung

- Không có bổ sung.

### Tóm tắt:

- **import requests**: Thư viện để gửi các yêu cầu HTTP.
- **from bs4 import BeautifulSoup**: Thư viện để phân tích cú pháp HTML.
- **requests.get(url)**: Gửi yêu cầu HTTP GET tới URL.
- **response.status_code**: Kiểm tra mã trạng thái phản hồi HTTP.
- **BeautifulSoup(response.content, 'html.parser')**: Phân tích nội dung HTML của phản hồi.
- **soup.find_all('a', href=True)**: Tìm tất cả các thẻ `<a>` có thuộc tính `href`.
- **links.append(link['href'])**: Thêm giá trị của thuộc tính `href` vào danh sách `links`.

Chương trình này trích xuất và in tất cả các liên kết từ một trang web mà người dùng nhập vào bằng cách sử dụng thư viện requests để gửi yêu cầu HTTP và BeautifulSoup để phân tích cú pháp HTML.
